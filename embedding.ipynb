{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['the', 'glass', 'of', 'milk'],\n",
       " ['the', 'glass', 'of', 'juice'],\n",
       " ['the', 'cup', 'of', 'tea'],\n",
       " ['I', 'am', 'a', 'good', 'boy'],\n",
       " ['I', 'am', 'a', 'good', 'developer'],\n",
       " ['understand', 'meaning', 'of', 'words'],\n",
       " ['video', 'are', 'crazy']]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = [\"the glass of milk\",\n",
    "             \"the glass of juice\",\n",
    "             \"the cup of tea\",\n",
    "             \"I am a good boy\",\n",
    "             \"I am a good developer\",\n",
    "             \"understand meaning of words\",\n",
    "             \"video are crazy\"]\n",
    "\n",
    "tokenized_sentences = [sentence.split() for sentence in sentences]\n",
    "tokenized_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'I',\n",
       " 'a',\n",
       " 'am',\n",
       " 'are',\n",
       " 'boy',\n",
       " 'crazy',\n",
       " 'cup',\n",
       " 'developer',\n",
       " 'glass',\n",
       " 'good',\n",
       " 'juice',\n",
       " 'meaning',\n",
       " 'milk',\n",
       " 'of',\n",
       " 'tea',\n",
       " 'the',\n",
       " 'understand',\n",
       " 'video',\n",
       " 'words'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_words = set(word for sentence in tokenized_sentences for word in sentence)\n",
    "unique_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'glass': 0,\n",
       " 'boy': 1,\n",
       " 'understand': 2,\n",
       " 'crazy': 3,\n",
       " 'developer': 4,\n",
       " 'the': 5,\n",
       " 'video': 6,\n",
       " 'good': 7,\n",
       " 'am': 8,\n",
       " 'meaning': 9,\n",
       " 'milk': 10,\n",
       " 'cup': 11,\n",
       " 'words': 12,\n",
       " 'juice': 13,\n",
       " 'a': 14,\n",
       " 'of': 15,\n",
       " 'are': 16,\n",
       " 'I': 17,\n",
       " 'tea': 18}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = {word: idx for idx, word in enumerate(unique_words)}\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([ 5,  0, 15, 10]),\n",
       " tensor([ 5,  0, 15, 13]),\n",
       " tensor([ 5, 11, 15, 18]),\n",
       " tensor([17,  8, 14,  7,  1]),\n",
       " tensor([17,  8, 14,  7,  4]),\n",
       " tensor([ 2,  9, 15, 12]),\n",
       " tensor([ 6, 16,  3])]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexed_sentences = [torch.tensor([vocab[word] for word in sentence]) for sentence in tokenized_sentences]\n",
    "indexed_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_39574/2453121432.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  indexed_tensors = [torch.tensor(sentence) for sentence in indexed_sentences]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[tensor([ 5,  0, 15, 10]),\n",
       " tensor([ 5,  0, 15, 13]),\n",
       " tensor([ 5, 11, 15, 18]),\n",
       " tensor([17,  8, 14,  7,  1]),\n",
       " tensor([17,  8, 14,  7,  4]),\n",
       " tensor([ 2,  9, 15, 12]),\n",
       " tensor([ 6, 16,  3])]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexed_tensors = [torch.tensor(sentence) for sentence in indexed_sentences]\n",
    "indexed_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5,  0, 15, 10,  0],\n",
       "        [ 5,  0, 15, 13,  0],\n",
       "        [ 5, 11, 15, 18,  0],\n",
       "        [17,  8, 14,  7,  1],\n",
       "        [17,  8, 14,  7,  4],\n",
       "        [ 2,  9, 15, 12,  0],\n",
       "        [ 6, 16,  3,  0,  0]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\n",
    "\n",
    "padded_sequences = pad_sequence(indexed_tensors, batch_first=True)  \n",
    "padded_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(100, 10)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = 100  # Assume a vocabulary of 100 words\n",
    "embedding_dim = 10  # Embedding size\n",
    "embedding = torch.nn.Embedding(vocab_size, embedding_dim)\n",
    "embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1563,  0.3374, -1.2173,  0.5870,  0.2763, -1.3092, -1.4945,\n",
       "           0.9227,  0.5266, -0.5911],\n",
       "         [-0.3922,  1.0005,  0.1720,  2.7476, -0.0382,  0.6005,  0.4771,\n",
       "           2.0407, -1.0554,  0.8217],\n",
       "         [-0.3766,  0.9352, -1.7333,  0.7318,  1.0319, -1.6682,  0.0359,\n",
       "           0.4202,  0.2748, -0.2647],\n",
       "         [ 0.2375,  0.5546, -1.4421,  0.4368, -1.6717,  0.6977, -0.7021,\n",
       "           1.0328,  0.1479, -1.4860],\n",
       "         [-0.3922,  1.0005,  0.1720,  2.7476, -0.0382,  0.6005,  0.4771,\n",
       "           2.0407, -1.0554,  0.8217]],\n",
       "\n",
       "        [[ 0.1563,  0.3374, -1.2173,  0.5870,  0.2763, -1.3092, -1.4945,\n",
       "           0.9227,  0.5266, -0.5911],\n",
       "         [-0.3922,  1.0005,  0.1720,  2.7476, -0.0382,  0.6005,  0.4771,\n",
       "           2.0407, -1.0554,  0.8217],\n",
       "         [-0.3766,  0.9352, -1.7333,  0.7318,  1.0319, -1.6682,  0.0359,\n",
       "           0.4202,  0.2748, -0.2647],\n",
       "         [ 0.8734, -1.2594,  1.5226, -1.6074, -0.5007, -0.3161, -0.2373,\n",
       "           0.8848, -2.0817, -0.6906],\n",
       "         [-0.3922,  1.0005,  0.1720,  2.7476, -0.0382,  0.6005,  0.4771,\n",
       "           2.0407, -1.0554,  0.8217]],\n",
       "\n",
       "        [[ 0.1563,  0.3374, -1.2173,  0.5870,  0.2763, -1.3092, -1.4945,\n",
       "           0.9227,  0.5266, -0.5911],\n",
       "         [-0.5986, -1.0853,  0.5510, -0.0427,  0.7596,  2.1584, -0.5933,\n",
       "           0.5122, -0.5063, -0.0554],\n",
       "         [-0.3766,  0.9352, -1.7333,  0.7318,  1.0319, -1.6682,  0.0359,\n",
       "           0.4202,  0.2748, -0.2647],\n",
       "         [-0.4179,  0.4736,  2.0427, -0.8071,  0.1145, -2.0520, -1.3894,\n",
       "           0.6152,  2.3475,  0.3398],\n",
       "         [-0.3922,  1.0005,  0.1720,  2.7476, -0.0382,  0.6005,  0.4771,\n",
       "           2.0407, -1.0554,  0.8217]],\n",
       "\n",
       "        [[-0.7376, -0.7721,  2.2966,  0.5202, -1.1166,  1.9041, -0.3225,\n",
       "          -0.6964, -1.6589, -0.0348],\n",
       "         [ 0.8929,  0.4045, -0.8677,  0.9968,  0.9180,  0.1607, -0.4428,\n",
       "           1.0170, -0.0810, -1.7367],\n",
       "         [-0.5909, -1.2954,  0.0639, -0.7865,  0.4320, -0.3858,  0.5028,\n",
       "          -1.1064, -0.8222, -0.7346],\n",
       "         [ 0.3145, -0.1324,  0.2656, -1.2615,  0.3661, -1.1798,  1.5654,\n",
       "          -1.9574,  0.9480,  0.1903],\n",
       "         [ 1.2646,  1.7446, -0.1456, -1.9481,  0.5260, -0.1096,  0.5516,\n",
       "           1.8428,  0.4590, -0.1607]],\n",
       "\n",
       "        [[-0.7376, -0.7721,  2.2966,  0.5202, -1.1166,  1.9041, -0.3225,\n",
       "          -0.6964, -1.6589, -0.0348],\n",
       "         [ 0.8929,  0.4045, -0.8677,  0.9968,  0.9180,  0.1607, -0.4428,\n",
       "           1.0170, -0.0810, -1.7367],\n",
       "         [-0.5909, -1.2954,  0.0639, -0.7865,  0.4320, -0.3858,  0.5028,\n",
       "          -1.1064, -0.8222, -0.7346],\n",
       "         [ 0.3145, -0.1324,  0.2656, -1.2615,  0.3661, -1.1798,  1.5654,\n",
       "          -1.9574,  0.9480,  0.1903],\n",
       "         [-0.4452, -1.0445, -0.6095, -1.5358, -1.4677,  1.0833, -0.4559,\n",
       "           0.3660,  0.4754, -0.4379]],\n",
       "\n",
       "        [[-0.2288,  0.8766, -0.1180,  0.2859,  0.0866,  0.8114, -0.9445,\n",
       "           0.7156,  1.1250, -0.7741],\n",
       "         [-0.7095,  1.1985, -0.7429, -0.2535, -0.3829,  1.7636, -1.1907,\n",
       "          -1.5278,  0.2156, -1.2419],\n",
       "         [-0.3766,  0.9352, -1.7333,  0.7318,  1.0319, -1.6682,  0.0359,\n",
       "           0.4202,  0.2748, -0.2647],\n",
       "         [-0.8836, -0.0136,  1.7296,  2.0168, -0.1670,  1.0460,  0.8393,\n",
       "           0.1633,  0.9288, -0.2647],\n",
       "         [-0.3922,  1.0005,  0.1720,  2.7476, -0.0382,  0.6005,  0.4771,\n",
       "           2.0407, -1.0554,  0.8217]],\n",
       "\n",
       "        [[ 1.0679, -0.0565,  1.7700, -0.7970,  1.5035,  2.7767,  2.6706,\n",
       "           0.9344,  0.0575, -0.0042],\n",
       "         [-0.2112,  1.1516,  0.8310, -0.2759, -1.3401, -1.0323,  0.0694,\n",
       "          -0.6596, -0.5661, -0.7119],\n",
       "         [-0.3250,  0.6613, -1.8829, -0.3906, -0.0578, -0.9951,  1.1260,\n",
       "           1.8629,  0.7226, -2.2626],\n",
       "         [-0.3922,  1.0005,  0.1720,  2.7476, -0.0382,  0.6005,  0.4771,\n",
       "           2.0407, -1.0554,  0.8217],\n",
       "         [-0.3922,  1.0005,  0.1720,  2.7476, -0.0382,  0.6005,  0.4771,\n",
       "           2.0407, -1.0554,  0.8217]]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_sequences = embedding(padded_sequences)\n",
    "embedded_sequences"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GenAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
